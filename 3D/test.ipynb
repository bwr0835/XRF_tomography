{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import dxchange\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch as tc\n",
    "tc.set_default_tensor_type(tc.FloatTensor)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib \n",
    "matplotlib.rcParams['pdf.fonttype'] = 'truetype'\n",
    "fontProperties = {'family': 'serif', 'serif': ['Helvetica'], 'weight': 'normal', 'size': 12}\n",
    "plt.rc('font', **fontProperties)\n",
    "\n",
    "from matplotlib import gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from tqdm import tqdm\n",
    "import xraylib as xlib\n",
    "import xraylib_np as xlib_np\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n",
      "<torch.utils.hooks.RemovableHandle object at 0x7f34a85cd550>\n"
     ]
    }
   ],
   "source": [
    "v = tc.tensor([0., 0., 0.], requires_grad=True)\n",
    "h = v.register_hook(lambda grad: grad * 2)  # double the gradient\n",
    "v.backward(tc.tensor([1., 2., 3.]))\n",
    "print(v.grad)\n",
    "print(h)\n",
    "h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]), tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])]\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n",
      "torch.Size([2, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "a = [tc.ones(5,5), tc.zeros(5,5)]\n",
    "\n",
    "b = tc.cat(a)\n",
    "\n",
    "c = b.view(2, 5, 5)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 207.61 MiB, increment: 0.01 MiB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 207.61 MiB, increment: 0.00 MiB\n",
      "peak memory: 207.62 MiB, increment: 0.00 MiB\n",
      "tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "                        1, 1, 1, 1, 1],\n",
      "                       [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 1,\n",
      "                        1, 2, 2, 2, 2],\n",
      "                       [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2,\n",
      "                        3, 0, 1, 2, 3]]),\n",
      "       values=tensor([-1.0125,  0.3158, -0.1862,  0.6274,  0.3387, -1.0906,\n",
      "                      -0.5354, -0.9119,  2.5889,  0.1097,  1.3429, -1.5578,\n",
      "                      -0.0369, -0.9621,  0.7963,  0.0056, -0.1278,  0.6980,\n",
      "                      -0.9804, -0.4895,  0.2319, -0.2586, -0.2572, -1.4562]),\n",
      "       size=(2, 3, 4), nnz=24, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "%memit a = tc.randn(2,3,4)\n",
    "%memit b = a.to_sparse()\n",
    "\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2],\n",
      "                       [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]]),\n",
      "       values=tensor([-1.0125,  0.3158, -0.1862,  0.6274,  0.3387, -1.0906,\n",
      "                      -0.5354, -0.9119,  2.5889,  0.1097,  1.3429, -1.5578]),\n",
      "       size=(3, 4), nnz=12, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.2973e-01, -2.7733e-01,  1.0535e-01, -1.3869e+00, -7.1109e-01,\n",
      "          2.6004e+00,  1.2107e+00,  8.8081e-01,  2.7330e+00,  7.1369e-01,\n",
      "         -5.2029e-01, -3.6804e-01,  9.9488e-01,  4.7041e-01, -8.9281e-01,\n",
      "         -1.3502e-01, -2.4221e-01, -1.7730e+00,  9.0124e-01, -1.0287e+00,\n",
      "         -3.6126e-01,  1.0021e+00,  2.7927e-02,  1.3905e+00, -3.8983e-01],\n",
      "        [ 6.3291e-01, -1.1631e+00, -1.8755e+00, -1.9081e+00, -1.5155e+00,\n",
      "         -5.6524e-01,  1.6773e-01,  5.2251e-01, -1.2864e+00, -1.9759e+00,\n",
      "          1.7271e-01,  1.6011e+00, -1.0264e+00, -6.3128e-01, -1.9373e+00,\n",
      "         -7.1016e-01,  5.8376e-02, -8.3885e-01, -5.5847e-01,  3.0197e-01,\n",
      "          1.8013e+00, -1.2079e+00,  1.4571e+00,  4.5037e-01, -1.3525e+00],\n",
      "        [-2.0682e+00, -1.2510e+00,  3.5495e-01,  4.4510e-01,  1.4809e-01,\n",
      "         -8.7417e-01,  6.1877e-01, -3.8223e-01,  3.7130e-01,  4.0550e-01,\n",
      "          1.3481e+00, -8.7916e-01,  1.1585e+00,  1.2979e+00,  1.1480e+00,\n",
      "          4.2168e-01,  5.2645e-01, -2.1905e+00, -1.2473e+00,  8.4630e-01,\n",
      "          9.1238e-01,  4.5045e-01, -1.2851e+00, -4.4158e-01, -1.8041e+00],\n",
      "        [-9.8674e-01, -1.2482e-01, -1.2498e+00, -3.4186e-01, -6.3760e-01,\n",
      "          1.8540e+00, -7.1319e-01,  6.2900e-01, -6.0458e-01, -7.7336e-01,\n",
      "          2.6156e-01,  2.4612e-01, -1.1760e+00, -3.2883e-02, -2.2655e+00,\n",
      "         -1.0121e-01,  4.9581e-01, -7.6018e-01, -1.1877e-01,  2.3338e-01,\n",
      "          8.1486e-01, -3.5168e-01, -6.5866e-01, -5.6805e-01, -1.0187e-02],\n",
      "        [ 1.0353e-01,  9.3145e-01, -1.0762e+00,  3.7956e-01, -2.2732e+00,\n",
      "         -5.6122e-01,  1.1791e+00, -4.5881e-01, -6.0485e-01,  3.5350e-01,\n",
      "          2.2099e-01, -6.6900e-01,  1.7712e+00,  6.8160e-01, -1.3113e+00,\n",
      "          1.5596e-01,  4.0938e-01, -1.0894e+00, -6.3873e-01,  3.5391e-01,\n",
      "          3.3787e-01,  3.5482e-02, -5.1198e-02,  2.6202e-02,  2.4075e-01],\n",
      "        [-3.6804e-02,  1.2596e+00,  1.4548e+00,  1.1291e+00, -1.0767e+00,\n",
      "         -8.6540e-01,  3.8753e-01,  8.0778e-01, -7.7552e-01, -1.4968e-01,\n",
      "          4.8251e-01,  2.9585e+00, -1.2911e+00,  6.1551e-01, -1.4731e+00,\n",
      "         -9.2946e-01,  4.0161e-01, -2.7594e+00,  6.4531e-01,  1.2906e+00,\n",
      "         -9.2724e-01,  9.2469e-01,  1.3398e+00,  5.3586e-01,  2.4808e-01],\n",
      "        [ 4.2205e-01, -1.1400e+00, -2.3077e+00,  9.7626e-01,  1.9498e+00,\n",
      "         -9.5504e-01,  1.6307e+00, -4.2217e-01,  8.1478e-01, -7.6543e-01,\n",
      "          8.7466e-02, -4.7947e-01, -2.7496e-01,  2.5083e+00, -1.6823e+00,\n",
      "         -9.9088e-01, -1.2905e-01, -4.9414e-01, -4.5069e-02, -3.6662e-01,\n",
      "          2.0892e-01, -1.1841e+00,  3.2057e-02,  5.7032e-01,  4.0316e-01],\n",
      "        [-1.0464e+00, -1.1315e-03,  7.9811e-01,  4.4321e-01,  1.2082e-01,\n",
      "          6.1665e-01,  1.0453e-02,  3.9263e-01, -4.1147e-01, -1.5359e+00,\n",
      "          1.7812e-01,  9.3296e-01,  8.5922e-01, -3.9029e-01,  1.0181e+00,\n",
      "         -1.5611e+00,  9.7800e-02, -1.5245e-01, -2.3430e-01,  9.5761e-01,\n",
      "          8.4673e-01,  7.9347e-01, -1.1082e+00,  7.2125e-01,  1.5948e+00],\n",
      "        [-1.6397e+00,  1.1524e+00,  2.0368e+00, -8.3236e-01,  2.7131e-01,\n",
      "          2.7414e-01,  3.7061e-01, -1.1714e+00,  1.0737e+00, -1.0236e-01,\n",
      "         -3.1759e-01,  9.2246e-01,  1.0881e-02, -1.8366e+00, -5.2361e-01,\n",
      "          2.9913e-02,  8.8430e-01, -4.9524e-02, -6.6976e-01, -1.5852e-01,\n",
      "          5.4626e-01, -9.9835e-01, -1.1114e-01, -2.0816e+00,  3.1027e-01],\n",
      "        [-1.1205e+00,  7.2657e-01,  8.1196e-01, -1.2642e+00,  1.5078e-01,\n",
      "         -1.3497e+00, -3.4893e-01,  3.4296e-02, -1.3756e+00, -5.2660e-01,\n",
      "         -5.5060e-01,  9.6953e-01, -9.4469e-01, -8.1219e-01, -1.5950e+00,\n",
      "          2.9428e-01, -1.9137e+00, -1.1187e+00, -1.6816e-01,  1.0445e+00,\n",
      "          2.5179e-01, -6.5605e-01, -4.8080e-01,  7.1351e-01,  8.1064e-01],\n",
      "        [ 5.0286e-02, -1.2865e+00, -3.9575e-01, -1.6921e+00, -5.8758e-01,\n",
      "          9.4136e-01,  1.8693e+00,  1.2100e+00, -1.7483e+00,  2.3077e+00,\n",
      "          6.3101e-01,  8.6417e-01, -1.1359e+00,  1.6433e+00, -7.0540e-01,\n",
      "          7.1126e-01,  4.7514e-01, -1.0126e+00,  3.1673e-02,  9.2967e-01,\n",
      "          7.3418e-01,  1.0129e+00,  1.4780e-01, -1.8050e+00, -7.5233e-02],\n",
      "        [ 1.1766e+00,  9.0551e-01,  4.7114e-01,  7.9100e-01,  1.4141e+00,\n",
      "         -1.7180e+00, -7.1194e-01,  3.6322e-01,  1.0083e+00,  9.4439e-01,\n",
      "         -1.1663e+00,  2.2063e+00,  8.0260e-01, -1.9139e+00, -1.2153e+00,\n",
      "          1.0095e+00, -8.9261e-01, -5.8348e-01,  7.6634e-01,  2.0856e-01,\n",
      "         -1.1256e+00,  1.9527e+00, -5.4049e-02, -2.5053e-01,  2.1524e-01],\n",
      "        [ 7.1314e-02,  1.1654e+00,  4.7255e-02, -1.7003e-01,  1.9660e+00,\n",
      "         -1.0339e+00, -1.5207e+00, -1.2693e+00, -3.5621e-01,  4.2996e-01,\n",
      "         -3.1736e-01, -9.9748e-01, -1.0355e-01, -1.5957e+00,  3.3116e-01,\n",
      "          4.9947e-01, -7.4982e-01, -8.9380e-01, -9.0509e-01,  1.3169e+00,\n",
      "         -5.1342e-01, -1.9004e-01,  2.1071e-01, -2.0861e+00,  7.8322e-01],\n",
      "        [ 7.5467e-01,  8.9507e-02,  2.3204e+00, -1.1138e+00,  1.3056e-01,\n",
      "         -1.4354e+00,  6.2628e-01,  1.0425e+00, -1.2437e+00, -9.4214e-01,\n",
      "          1.0447e+00, -1.1417e-01, -2.2305e-01,  1.3278e-01, -4.1802e-01,\n",
      "          1.5123e-01,  3.0848e-01, -1.4167e+00, -5.7121e-01, -3.4044e-01,\n",
      "          2.8257e-01, -7.5540e-01,  5.9900e-01, -2.5663e-01, -6.5588e-01],\n",
      "        [-2.4115e+00, -1.0733e+00,  5.2668e-01, -1.2147e+00,  7.3824e-01,\n",
      "          3.7937e-01, -2.4248e+00, -1.1753e+00,  6.7622e-01,  8.9487e-01,\n",
      "          5.5878e-01, -7.0209e-01, -3.3615e-01, -7.6872e-01, -1.8109e+00,\n",
      "          5.8776e-01,  1.2764e+00,  6.4915e-01, -1.8517e+00, -1.7690e+00,\n",
      "         -9.0264e-01, -1.4439e+00, -9.8902e-02, -7.2956e-01,  1.0601e+00],\n",
      "        [ 4.2750e-01,  1.1587e+00, -1.8844e+00,  1.7067e+00, -1.4501e+00,\n",
      "         -7.6329e-01,  2.3067e+00,  5.8359e-02, -2.4256e-01,  4.5140e-01,\n",
      "         -2.6787e-01,  5.8683e-01, -1.5614e+00,  2.7175e+00, -1.3196e+00,\n",
      "         -2.1281e-01, -1.3233e-02, -4.2309e-01, -3.6741e-01, -2.0070e+00,\n",
      "         -6.8477e-02,  2.7456e-02, -1.6703e+00,  4.8471e-01, -2.0703e-01],\n",
      "        [ 7.4538e-01,  1.1811e-01, -8.4535e-01, -2.8918e-01,  9.8828e-01,\n",
      "         -1.9395e+00,  6.1706e-01, -1.9664e+00, -1.8371e-01,  4.9983e-01,\n",
      "         -1.2841e-01, -5.0491e-01, -3.5731e-01,  1.9533e+00, -1.5358e+00,\n",
      "         -1.3981e-01, -1.5099e+00, -5.9041e-01,  1.1511e-01, -3.8488e-01,\n",
      "         -2.1513e+00, -1.1758e+00, -1.5761e+00,  1.5892e-01, -4.8301e-01],\n",
      "        [-1.0827e+00, -2.3963e-01,  1.2785e+00,  1.3436e+00, -8.7238e-01,\n",
      "         -9.9748e-01, -2.5623e-01, -2.4338e-01, -1.6663e+00,  6.9217e-01,\n",
      "          1.9291e-01, -7.5898e-01,  1.1241e+00, -3.6341e-01,  7.5126e-01,\n",
      "         -2.4779e+00,  1.1850e+00,  1.3232e+00, -7.8259e-01, -2.5403e-03,\n",
      "         -1.4210e+00, -1.9293e-01,  1.8341e-01,  2.6508e-01, -5.3866e-02],\n",
      "        [ 4.3781e-01,  9.0876e-01,  9.2132e-01,  1.2935e+00, -8.9272e-01,\n",
      "          1.8767e+00, -1.2881e-01,  7.8202e-01, -9.9333e-01, -1.6404e-01,\n",
      "          1.9033e+00, -1.6616e+00,  1.2486e+00, -6.0224e-01,  9.4606e-02,\n",
      "         -5.9091e-01,  9.2299e-01, -1.4517e+00, -2.0808e+00,  5.3292e-02,\n",
      "         -1.2434e+00, -1.7782e+00, -7.6949e-01,  5.0008e-01,  1.9642e+00],\n",
      "        [ 8.7086e-01,  1.2694e+00,  6.6752e-01, -2.1029e-01,  4.9652e-01,\n",
      "          2.6808e-01,  1.3446e+00,  1.1992e+00, -6.4224e-01,  6.2540e-01,\n",
      "          1.6611e-01,  2.0348e+00, -3.0841e-01, -7.8203e-01, -4.3798e-02,\n",
      "          1.3928e+00, -8.0930e-01,  9.5541e-01, -1.2037e+00, -3.9940e-02,\n",
      "          2.9189e-01, -3.3981e-02, -6.7791e-02,  1.9184e+00, -6.0186e-01],\n",
      "        [-9.0669e-01, -4.4313e-01, -4.8935e-01, -1.4848e+00,  1.7939e+00,\n",
      "          9.4032e-01,  1.9738e+00,  1.0840e+00,  1.5158e-01, -2.0146e+00,\n",
      "         -1.6533e-01, -1.7100e+00,  2.1267e-01, -1.0161e+00,  2.1943e-01,\n",
      "          1.7147e-01, -5.4737e-01, -2.8592e-01, -6.0098e-01, -1.0061e+00,\n",
      "          2.1399e+00, -7.5505e-01, -1.3097e-01,  1.4415e-01, -5.1255e-01],\n",
      "        [-2.9011e-01, -1.2531e-01, -8.8291e-01, -1.0551e+00,  1.1663e+00,\n",
      "         -3.7561e-02,  1.2766e-01, -4.0281e-01,  6.7452e-02, -4.7157e-01,\n",
      "          5.1027e-01, -4.9950e-01, -3.9776e-02, -1.2006e+00,  2.7890e-01,\n",
      "         -8.2775e-02,  2.9761e-01, -3.0481e-01, -2.5357e+00,  5.8930e-01,\n",
      "          1.4837e+00,  1.1304e-01, -5.5368e-01, -1.0832e+00,  1.2767e+00],\n",
      "        [ 1.9501e-01, -9.0548e-01,  1.6531e+00, -9.9966e-01, -9.0791e-01,\n",
      "         -7.2758e-03,  1.0115e+00, -2.1843e-01,  5.3980e-01, -1.1720e+00,\n",
      "         -1.3182e+00, -8.1190e-01, -1.7577e+00,  6.6415e-01, -9.0134e-01,\n",
      "         -4.6153e-01,  1.5801e+00,  3.5711e-01,  8.2760e-01, -1.5151e+00,\n",
      "          1.9720e+00,  6.3584e-02, -1.0818e+00,  2.7562e-01,  9.1681e-01],\n",
      "        [-2.2343e+00,  7.8271e-01,  3.0042e-01, -3.5244e-01,  2.4897e+00,\n",
      "          1.8707e+00,  9.5730e-01,  1.2083e+00, -2.9037e-01, -5.7028e-01,\n",
      "         -1.4148e+00,  3.2903e-01,  9.4257e-03,  4.7010e-01,  6.3785e-01,\n",
      "          1.9317e-01,  5.1704e-02,  5.8961e-01,  3.9068e-01,  9.2624e-01,\n",
      "          1.1737e+00, -3.9422e-02,  1.2166e+00,  1.8723e-01,  6.0153e-01],\n",
      "        [ 6.0849e-01,  8.3581e-01, -1.9838e+00,  1.1251e+00,  1.7786e+00,\n",
      "          3.3691e-01, -1.1162e+00,  1.8225e-01, -1.5537e+00,  1.3348e+00,\n",
      "         -1.5334e+00,  6.9308e-02,  9.3646e-01, -6.1635e-01, -4.5569e-01,\n",
      "          3.4007e-01,  1.0092e+00, -1.7893e+00,  1.3370e+00, -1.2948e+00,\n",
      "          1.3206e+00, -1.9275e+00, -1.0084e+00,  1.2559e+00, -1.2083e-01]])\n",
      "tensor([[[-0.7297, -0.2773,  0.1053, -1.3869, -0.7111,  2.6004,  1.2107,\n",
      "           0.8808,  2.7330,  0.7137, -0.5203, -0.3680,  0.9949,  0.4704,\n",
      "          -0.8928, -0.1350, -0.2422, -1.7730,  0.9012, -1.0287, -0.3613,\n",
      "           1.0021,  0.0279,  1.3905, -0.3898],\n",
      "         [-0.7297, -0.2773,  0.1053, -1.3869, -0.7111,  2.6004,  1.2107,\n",
      "           0.8808,  2.7330,  0.7137, -0.5203, -0.3680,  0.9949,  0.4704,\n",
      "          -0.8928, -0.1350, -0.2422, -1.7730,  0.9012, -1.0287, -0.3613,\n",
      "           1.0021,  0.0279,  1.3905, -0.3898],\n",
      "         [-0.7297, -0.2773,  0.1053, -1.3869, -0.7111,  2.6004,  1.2107,\n",
      "           0.8808,  2.7330,  0.7137, -0.5203, -0.3680,  0.9949,  0.4704,\n",
      "          -0.8928, -0.1350, -0.2422, -1.7730,  0.9012, -1.0287, -0.3613,\n",
      "           1.0021,  0.0279,  1.3905, -0.3898]],\n",
      "\n",
      "        [[-0.0368,  1.2596,  1.4548,  1.1291, -1.0767, -0.8654,  0.3875,\n",
      "           0.8078, -0.7755, -0.1497,  0.4825,  2.9585, -1.2911,  0.6155,\n",
      "          -1.4731, -0.9295,  0.4016, -2.7594,  0.6453,  1.2906, -0.9272,\n",
      "           0.9247,  1.3398,  0.5359,  0.2481],\n",
      "         [ 0.0503, -1.2865, -0.3957, -1.6921, -0.5876,  0.9414,  1.8693,\n",
      "           1.2100, -1.7483,  2.3077,  0.6310,  0.8642, -1.1359,  1.6433,\n",
      "          -0.7054,  0.7113,  0.4751, -1.0126,  0.0317,  0.9297,  0.7342,\n",
      "           1.0129,  0.1478, -1.8050, -0.0752],\n",
      "         [ 0.4275,  1.1587, -1.8844,  1.7067, -1.4501, -0.7633,  2.3067,\n",
      "           0.0584, -0.2426,  0.4514, -0.2679,  0.5868, -1.5614,  2.7175,\n",
      "          -1.3196, -0.2128, -0.0132, -0.4231, -0.3674, -2.0070, -0.0685,\n",
      "           0.0275, -1.6703,  0.4847, -0.2070]]])\n"
     ]
    }
   ],
   "source": [
    "a = tc.randn(25,25)\n",
    "b = tc.tensor([[0,0,0],[5,10,15]])\n",
    "print(a)\n",
    "print(a[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell solves the intersection of a ray with a plane \n",
    "### There're 3 types of plane x = some constant (d_x), y = some constant (d_y) and z = some constant (d_z)\n",
    "### The correspoinding intersecting points can be solved using trace_beam_x, trace_beam_y, trace_beam_z respectively\n",
    "\n",
    "# The ray using a parametric form with a parameter, t: R(t) = (1-t) * S + t * D \n",
    "# The intersecting coordinates: (x, y, z) = (Ix, Iy, Iz) at t=t*\n",
    "\n",
    "# Define the system of equation AX = b to solve the intersecting, A is with the dimension: (n_batch, 4, 4), b is with the dimension: (n_batch, 4, 1)\n",
    "# n_batch is the number of planes we put into the equation that we want to solve the intersecting point with the the ray\n",
    "\n",
    "def trace_beam_z(z_s, x_s, y_s, z_d, x_d, y_d, d_z_ls):\n",
    "    if len(d_z_ls) == 0 or z_s == z_d:\n",
    "        Z = np.stack((np.array([]), np.array([]), np.array([])), axis=-1)\n",
    "    else:\n",
    "        A = tc.tensor([[1, 0, 0, z_s - z_d],[0, 1, 0, x_s - x_d],[0, 0, 1, y_s - y_d],[1, 0, 0, 0]])\n",
    "        A = A.repeat([len(d_z_ls), 1, 1])\n",
    "\n",
    "        b1 = tc.tensor([[[z_s], [x_s], [y_s]]]).repeat([len(d_z_ls), 1, 1])\n",
    "        b2 = tc.tensor([[[d_z]] for d_z in d_z_ls])\n",
    "        b = tc.cat((b1, b2), dim=1)\n",
    "\n",
    "        Z, LU = tc.solve(b, A)\n",
    "        Z = np.array(Z[:,:-1].view(len(d_z_ls), 3))\n",
    "#         t = X[:,-1] \n",
    "    \n",
    "    return Z\n",
    "\n",
    "def trace_beam_x(z_s, x_s, y_s, z_d, x_d, y_d, d_x_ls):\n",
    "    if len(d_x_ls) == 0:\n",
    "        X = np.stack((np.array([]), np.array([]), np.array([])), axis=-1)\n",
    "    else:    \n",
    "        A = tc.tensor([[1, 0, 0, z_s - z_d],[0, 1, 0, x_s - x_d],[0, 0, 1, y_s - y_d],[0, 1, 0, 0]])\n",
    "        A = A.repeat([len(d_x_ls), 1, 1])\n",
    "\n",
    "        b1 = tc.tensor([[[z_s], [x_s], [y_s]]]).repeat([len(d_x_ls), 1, 1])\n",
    "        b2 = tc.tensor([[[d_x]] for d_x in d_x_ls])\n",
    "        b = tc.cat((b1, b2), dim=1)\n",
    "\n",
    "        X, LU = tc.solve(b, A)\n",
    "        X = np.array(X[:,:-1].view(len(d_x_ls), 3))\n",
    "#         t = Y[:,-1]\n",
    "    \n",
    "    return X\n",
    "\n",
    "def trace_beam_y(z_s, x_s, y_s, z_d, x_d, y_d, d_y_ls):\n",
    "    if len(d_y_ls) == 0 or y_s == y_d:\n",
    "        Y = np.stack((np.array([]), np.array([]), np.array([])), axis=-1)\n",
    "    else:\n",
    "        A = tc.tensor([[1, 0, 0, z_s - z_d],[0, 1, 0, x_s - x_d],[0, 0, 1, y_s - y_d],[0, 0, 1, 0]])\n",
    "        A = A.repeat([len(d_y_ls), 1, 1])\n",
    "\n",
    "        b1 = tc.tensor([[[z_s], [x_s], [y_s]]]).repeat([len(d_y_ls), 1, 1])\n",
    "        b2 = tc.tensor([[[d_y]] for d_y in d_y_ls])\n",
    "        b = tc.cat((b1, b2), dim=1)\n",
    "\n",
    "        Y, LU = tc.solve(b, A)\n",
    "        Y = np.array(Y[:,:-1].view(len(d_y_ls), 3))\n",
    "#         t = Z[:,-1]\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersecting_length_fl_detectorlet_3d(det_size_cm, det_from_sample_cm, det_ds_spacing_cm, sample_size_n, sample_size_cm, sample_height_n, P_save_path):\n",
    "    if os.path.isfile(P_save_path):\n",
    "        with open(P_save_path, \"rb\") as myFile:\n",
    "            P = pickle.load(myFile)\n",
    "        n_det = P.shape[0]\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        ### Calculating voxel size in cm\n",
    "        voxel_size_cm = sample_size_cm/sample_size_n\n",
    "\n",
    "        ### Calculating the diameter of the XRF detector with \n",
    "        det_size_n = int(np.ceil(det_size_cm/voxel_size_cm)) \n",
    "\n",
    "        ### Set the desired spacing between detectorlets, and then convert the unit of spacing to the number of the sample voxels\n",
    "        det_ds_spacing_cm = 0.1\n",
    "        det_ds_spacing_n = int(det_ds_spacing_cm/voxel_size_cm)\n",
    "\n",
    "        # Define position of center of the source voxel (z_s, x_s, y_s), note that it's shifted by 0.5 from the voxel idx to represent the loc of center\n",
    "        z_s, x_s, y_s = np.indices((int(sample_height_n), int(sample_size_n), int(sample_size_n))) + 0.5\n",
    "        voxel_pos_ls_flat = np.stack((z_s.flatten(), x_s.flatten(), y_s.flatten()), axis=-1)\n",
    "\n",
    "\n",
    "        ### Define the location of the detectorlets, the detector is parallel to the yz-plane\n",
    "        ### The x-posision depends on the distance between the sample and the detecor\n",
    "        ## x index of the location of the XRF detector\n",
    "        det_axis_1_idx = sample_size_n + np.ceil(det_from_sample_cm/voxel_size_cm) + 0.5\n",
    "\n",
    "        ### y, z index of the location of the XRF detector\n",
    "        ## Define the center of the detector on yz-plane\n",
    "        det_center_yz = (int(sample_size_n)/2., int(sample_size_n)/2.)\n",
    "\n",
    "        ## Define the y and z loc(namely the loc along axis 2 and axis 0) of the detectorlets. The y and z loc are confined to be within a circle on the yz plane\n",
    "        end_det_axis_2_idx_ls = np.array([int((sample_size_n - det_ds_spacing_n * np.floor(det_size_n/det_ds_spacing_n))/2.),\n",
    "                                          int((sample_size_n + det_ds_spacing_n * np.floor(det_size_n/det_ds_spacing_n))/2.)])\n",
    "\n",
    "        det_axis_2_idx_ls = np.linspace(end_det_axis_2_idx_ls[0], end_det_axis_2_idx_ls[1], np.int(det_size_n/det_ds_spacing_n + 1))\n",
    "\n",
    "\n",
    "        end_det_axis_0_idx_ls = np.array([int((sample_height_n - det_ds_spacing_n * np.floor(det_size_n/det_ds_spacing_n))/2.),\n",
    "                                          int((sample_height_n + det_ds_spacing_n * np.floor(det_size_n/det_ds_spacing_n))/2.)])\n",
    "\n",
    "        det_axis_0_idx_ls = np.linspace(end_det_axis_0_idx_ls[0], end_det_axis_0_idx_ls[1], np.int(det_size_n/det_ds_spacing_n + 1))\n",
    "\n",
    "        ## Create the meshgrid of y and z coordinates and keep only the coordinates within the detector circle\n",
    "        y_d, z_d = np.meshgrid(det_axis_2_idx_ls, det_axis_0_idx_ls)\n",
    "\n",
    "        yz_mask = ((y_d - det_center_yz[0])**2 + (z_d - det_center_yz[1])**2 <= (det_size_n/2)**2).flatten()\n",
    "        y_d_flat, z_d_flat = y_d.flatten()[yz_mask], z_d.flatten()[yz_mask]\n",
    "\n",
    "\n",
    "        ## The number of x posision needed to fill into the coodinates depends on the number of the y(or z) coodinates within the circle of detector\n",
    "        x_d_flat = np.full((y_d_flat.shape), det_axis_1_idx)\n",
    "\n",
    "        ##\n",
    "        det_pos_ls_flat = np.stack((z_d_flat, x_d_flat, y_d_flat), axis=-1)\n",
    "        n_det = len(det_pos_ls_flat)\n",
    "\n",
    "        ## define sample edges: \n",
    "        ## sample_x_edge is the edge that is closer to the XRF detector\n",
    "        ## sample_y_edge has two components representing the left and the right edge\n",
    "        sample_x_edge = np.array([sample_size_n])\n",
    "        sample_y_edge = np.array([0, sample_size_n]) \n",
    "        sample_z_edge = np.array([0, sample_height_n]) \n",
    "\n",
    "        # P = np.zeros((n_det, sample_height_n * sample_size_n * sample_size_n, sample_height_n * sample_size_n * sample_size_n), dtype=np.float32)\n",
    "        dia_len_n = int((sample_height_n**2 + sample_size_n**2 + sample_size_n**2)**0.5)\n",
    "        P = tc.zeros(n_det, 3, dia_len_n * sample_height_n * sample_size_n**2)\n",
    "#         Q = tc.zeros(3, sample_height_n * sample_size_n**2 * dia_len_n)\n",
    "        \n",
    "        for i,  det_pos in enumerate(det_pos_ls_flat):\n",
    "            for j, v in enumerate(tqdm(voxel_pos_ls_flat)): \n",
    "\n",
    "                # Solving the intersection of the ray with the sample boundary along axis-0\n",
    "                bdx_int = trace_beam_x(v[0], v[1], v[2], det_pos[0], det_pos[1], det_pos[2], sample_x_edge) # pick the 0th component just because the coordinate is doubly braced\n",
    "\n",
    "                # Solving the intersection of the ray with the sample boundaries along axis-1 and axis-2, we will get 2 solutions for each axis since there're 2 bdry plane on each axis\n",
    "                # The desired intersecting point is within the segment(voxel - detectorlet) which is always the one with the larger x coordinate\n",
    "                bdy_int = trace_beam_y(v[0], v[1], v[2], det_pos[0], det_pos[1], det_pos[2], sample_y_edge)\n",
    "                if len(bdy_int) != 0:\n",
    "                    bdy_int = np.array([bdy_int[np.argmax(bdy_int[:,1])]])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "                bdz_int = trace_beam_z(v[0], v[1], v[2], det_pos[0], det_pos[1], det_pos[2], sample_z_edge)\n",
    "                if len(bdz_int) != 0:\n",
    "                    bdz_int = np.array([bdz_int[np.argmax(bdz_int[:,1])]])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                # Pick the intersecting point that first hit the boundary plan. This point is with the least x value among the 3 intersections.\n",
    "                bd_int_ls = np.concatenate((bdz_int, bdx_int, bdy_int))\n",
    "                bd_int = np.clip(np.abs((bd_int_ls[np.argmin(bd_int_ls[:,1])])), 0, sample_size_n)\n",
    "\n",
    "\n",
    "                # when the beam intersects with a voxel, it either intersects with the x or y or z boundary plane of the voxel\n",
    "                # find the x,y,z-value of the voxel boundary except the ones on the sample edge\n",
    "\n",
    "                z_edge_ls = np.where(bd_int[0] > v[0], np.linspace(np.ceil(bd_int[0])-1, np.ceil(v[0]), int(np.abs(np.ceil(bd_int[0]) - np.ceil(v[0])))),\n",
    "                                                       np.linspace(np.ceil(v[0])-1, np.ceil(bd_int[0]), int(np.abs(np.ceil(bd_int[0]) - np.ceil(v[0])))))\n",
    "\n",
    "                x_edge_ls = np.where(bd_int[1] > v[1], np.linspace(np.ceil(bd_int[1])-1, np.ceil(v[1]), int(np.abs(np.ceil(bd_int[1]) - np.ceil(v[1])))),\n",
    "                                                       np.linspace(np.ceil(v[1])-1, np.ceil(bd_int[1]), int(np.abs(np.ceil(bd_int[1]) - np.ceil(v[1])))))\n",
    "\n",
    "                y_edge_ls = np.where(bd_int[2] > v[2], np.linspace(np.ceil(bd_int[2])-1, np.ceil(v[2]), int(np.abs(np.ceil(bd_int[2]) - np.ceil(v[2])))),\n",
    "                                                       np.linspace(np.ceil(v[2])-1, np.ceil(bd_int[2]), int(np.abs(np.ceil(bd_int[2]) - np.ceil(v[2])))))\n",
    "\n",
    "\n",
    "                z_edge_int_ls = trace_beam_z(v[0], v[1], v[2], det_pos[0], det_pos[1], det_pos[2], z_edge_ls)\n",
    "                x_edge_int_ls = trace_beam_x(v[0], v[1], v[2], det_pos[0], det_pos[1], det_pos[2], x_edge_ls)\n",
    "                y_edge_int_ls = trace_beam_y(v[0], v[1], v[2], det_pos[0], det_pos[1], det_pos[2], y_edge_ls)\n",
    "\n",
    "                # Collect all intersecting points and sort all intersections using the x coordinate\n",
    "                int_ls = np.concatenate((x_edge_int_ls, y_edge_int_ls, z_edge_int_ls, np.array(bd_int)[np.newaxis,:]))     \n",
    "                int_ls = int_ls[np.argsort(int_ls[:,1])]\n",
    "\n",
    "                # calculate the intersecting length in the intersecting voxels\n",
    "                int_length = np.sqrt(np.diff(int_ls[:,0])**2 + np.diff(int_ls[:,1])**2 + np.diff(int_ls[:,2])**2)\n",
    "                # just in case that we count some intersections twice, delete the duplicates\n",
    "                idx_duplicate = np.array(np.where(int_length==0)).flatten()\n",
    "                int_ls = np.delete(int_ls, idx_duplicate, 0)\n",
    "                int_length = np.delete(int_length, idx_duplicate) \n",
    "\n",
    "                # determine the indices of the intersecting voxels according to the intersecting x,y,z-coordinates\n",
    "                int_ls_shift = np.zeros((int_ls.shape))\n",
    "                int_ls_shift[1:] = int_ls[:-1]\n",
    "                int_idx = np.floor((int_ls + int_ls_shift)/2)[1:]\n",
    "#                 int_idx = (int_idx[:,0].astype('int'), int_idx[:,1].astype('int'), int_idx[:,2].astype('int'))\n",
    "                int_idx_flat = int_idx[:,0] * (sample_height_n.item() * sample_size_n.item()) + int_idx[:,1] * sample_size_n.item() + int_idx[:,2]\n",
    "    \n",
    "                \n",
    "                P[i, 0, j * dia_len_n: j * dia_len_n + len(int_idx_flat)] = j\n",
    "                P[i, 1, j * dia_len_n: j * dia_len_n + len(int_idx_flat)] = tc.tensor(int_idx_flat)\n",
    "                P[i, 2, j * dia_len_n: j * dia_len_n + len(int_idx_flat)] = tc.tensor(int_length * voxel_size_cm.item())            \n",
    "                                \n",
    "                tqdm._instances.clear()\n",
    "             \n",
    "        with open(P_save_path, \"wb\") as myFile:\n",
    "            pickle.dump(P, myFile)\n",
    "    return n_det, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For a 64 x 64 x 64 sample: sample1 ##\n",
    "######################################################################\n",
    "# experiemtal parameters #\n",
    "dev = 'cpu'\n",
    "theta_st = tc.tensor(0).to(dev)\n",
    "theta_end = tc.tensor(2 * np.pi).to(dev)\n",
    "n_theta =  tc.tensor(200).to(dev)\n",
    "theta_ls = - tc.linspace(theta_st, theta_end, n_theta+1)[:-1].to(dev)\n",
    "sample_size_n = tc.tensor(64).to(dev)\n",
    "sample_height_n = tc.tensor(64).to(dev)\n",
    "sample_size_cm = tc.tensor(0.01).to(dev)\n",
    "this_aN_dic = {\"C\": 6, \"O\": 8, \"Si\": 14, \"Ca\": 20, \"Fe\": 26}\n",
    "probe_energy = np.array([20.0])\n",
    "probe_cts = tc.tensor(1.0E7).to(dev)\n",
    "det_size_cm = 0.24\n",
    "det_from_sample_cm = 1.6\n",
    "det_ds_spacing_cm = 0.1\n",
    "\n",
    "# path of true grid concentration of the sample #\n",
    "grid_path = './data/sample1_pad'\n",
    "f_grid = 'grid_concentration.npy'\n",
    "\n",
    "# XRF and XRT data path #\n",
    "data_path = './data/sample1_data'\n",
    "f_XRF_data = 'XRF_sample1'\n",
    "f_XRT_data = 'XRT_sample1'\n",
    "\n",
    "# path of storing the intersecting information and the reconstructing results #\n",
    "recon_path = 'data/sample1_recon'\n",
    "if not os.path.exists(recon_path):\n",
    "    os.mkdir(recon_path)\n",
    "P_save_path = os.path.join(recon_path, 'Intersecting_Length_64_64_64')\n",
    "f_recon_parameters = 'recon_parameters.txt'\n",
    "f_recon_grid = 'grid_concentration'\n",
    "f_initial_guess = 'initialized_grid_concentration'\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_det, P = intersecting_length_fl_detectorlet_3d(det_size_cm, det_from_sample_cm, det_ds_spacing_cm,\n",
    "                                          sample_size_n.cpu().numpy(), sample_size_cm.cpu().numpy(),\n",
    "                                          sample_height_n.cpu().numpy(), P_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
